{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1LID4_TqfJRTlGJY5ob0iE11UkhUuWnU5",
      "authorship_tag": "ABX9TyM9XYGVeDVEeB+MJe3NLI+a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucassantillifuck2fa/Music-Source-Separation-Training/blob/main/Phase_Fixer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=6>Phase Fixer for Unwa Roformers</font><br>\n",
        "Powered by ZFTurbo's [Music-Source-Separation-Training](https://github.com/ZFTurbo/Music-Source-Separation-Training/)\n",
        "\n",
        "<font size=1>*Based on the colab provided by [jarredou](https://github.com/jarredou) & deton</font>"
      ],
      "metadata": {
        "id": "JInUe6DSffTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Install\n",
        "\n",
        "import base64\n",
        "import requests\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "if not os.path.exists('/content/Music-Source-Separation-Training'):\n",
        "  print('Cloning MSST repository...')\n",
        "  !git clone -b colab-inference https://github.com/lucassantillifuck2fa/Music-Source-Separation-Training\n",
        "  !mkdir '/content/Music-Source-Separation-Training/ckpts'\n",
        "\n",
        "%cd /content\n",
        "clear_output()\n",
        "\n",
        "print('Installing the dependencies... This will take few minutes')\n",
        "!pip install -r 'Music-Source-Separation-Training/requirements.txt' &> /dev/null\n",
        "print('Installation is done !')"
      ],
      "metadata": {
        "id": "33IsG9fQfjwJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/Music-Source-Separation-Training/'\n",
        "clear_output()\n",
        "import os\n",
        "import torch\n",
        "import yaml\n",
        "from urllib.parse import quote\n",
        "import subprocess\n",
        "import time\n",
        "import sys\n",
        "from IPython.display import clear_output\n",
        "extensions = (\".wav\", \".mp3\", \".m4a\", \".weba\", \".flac\", \".ogg\", \".mp4\", \".webv\", \".opus\", \".m4v\", \".avi\", \".mpg\", \".mkv\")\n",
        "\n",
        "class IndentDumper(yaml.Dumper):\n",
        "    def increase_indent(self, flow=False, indentless=False):\n",
        "        return super(IndentDumper, self).increase_indent(flow, False)\n",
        "\n",
        "def tuple_constructor(loader, node):\n",
        "    # Load the sequence of values from the YAML node\n",
        "    values = loader.construct_sequence(node)\n",
        "    # Return a tuple constructed from the sequence\n",
        "    return tuple(values)\n",
        "\n",
        "# Register the constructor with PyYAML\n",
        "yaml.SafeLoader.add_constructor('tag:yaml.org,2002:python/tuple',\n",
        "tuple_constructor)\n",
        "\n",
        "def conf_edit(config_path, chunk_size, overlap):\n",
        "    with open(config_path, 'r') as f:\n",
        "        data = yaml.load(f, Loader=yaml.SafeLoader)\n",
        "\n",
        "    # handle cases where 'use_amp' is missing from config:\n",
        "    if 'use_amp' not in data.keys():\n",
        "      data['training']['use_amp'] = True\n",
        "\n",
        "    data['audio']['chunk_size'] = chunk_size\n",
        "    data['inference']['num_overlap'] = overlap\n",
        "\n",
        "    if data['inference']['batch_size'] == 1:\n",
        "      data['inference']['batch_size'] = 2\n",
        "\n",
        "    print(\"Using custom overlap and chunk_size values:\")\n",
        "    print(f\"overlap = {data['inference']['num_overlap']}\")\n",
        "    print(f\"chunk_size = {data['audio']['chunk_size']}\")\n",
        "    print(f\"batch_size = {data['inference']['batch_size']}\")\n",
        "\n",
        "    with open(config_path, 'w') as f:\n",
        "        yaml.dump(data, f, default_flow_style=False, sort_keys=False, Dumper=IndentDumper, allow_unicode=True)\n",
        "\n",
        "def download_file(url):\n",
        "    # Encode the URL to handle spaces and special characters\n",
        "    encoded_url = quote(url, safe=':/')\n",
        "\n",
        "    path = 'ckpts'\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    filename = os.path.basename(encoded_url)\n",
        "    file_path = os.path.join(path, filename)\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        response = torch.hub.download_url_to_file(encoded_url, file_path)\n",
        "        print(f\"File '{filename}' downloaded successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading file '{filename}' from '{url}': {e}\")\n",
        "\n",
        "#@markdown # Separation\n",
        "#@markdown #### Separation config:\n",
        "input = '/content/drive/MyDrive/songs/' #@param {type:\"string\"}\n",
        "output_folder = '/content/drive/MyDrive/separated' #@param {type:\"string\"}\n",
        "#@markdown\n",
        "base_model = 'VOCALS-MelBand-Roformer (by Becruily)' #@param ['VOCALS-MelBand-Roformer (by Becruily)', 'VOCALS-BS-Roformer_1296 (by viperx)', 'VOCALS-BS-Roformer_1297 (by viperx)', 'VOCALS-MelBand-Roformer Kim FT (by Unwa)', 'VOCALS-BS-RoformerLargev1 (by unwa)', 'VOCALS-Melband-Roformer BigBeta5e (by unwa)', 'VOCALS-Mel-Roformer big beta 4 (by unwa)']\n",
        "unwa_model = 'INST-MelBand-Roformer (by Becruily)' #@param ['INST-MelBand-Roformer (by Becruily)', 'INST-Mel-Roformer v1 (by unwa)','INST-Mel-Roformer v2 (by unwa)', 'INST-Mel-Roformer v1e (by unwa)', 'INST-VOC-Mel-Roformer a.k.a. duality (by unwa)', 'INST-VOC-Mel-Roformer a.k.a. duality v2 (by unwa)']\n",
        "export_format = 'flac PCM_16' #@param ['wav FLOAT', 'flac PCM_16', 'flac PCM_24']\n",
        "#@markdown ---\n",
        "#@markdown *Roformers custom config:*\n",
        "overlap = 2 #@param {type:\"slider\", min:2, max:40, step:1}\n",
        "chunk_size = 485100 #@param [132300, 352800, 485100] {type:\"raw\"}\n",
        "base_inference = True # @param {\"type\":\"boolean\"}\n",
        "unwa_inference = True # @param {\"type\":\"boolean\"}\n",
        "#phasefix_testmode = True # @param {\"type\":\"boolean\"}\n",
        "\n",
        "if export_format.startswith('flac'):\n",
        "    flac_file = True\n",
        "    pcm_type = export_format.split(' ')[1]\n",
        "else:\n",
        "    flac_file = False\n",
        "    pcm_type = None\n",
        "\n",
        "\n",
        "output_base = f\"{output_folder}/base\"\n",
        "output_unwa = f\"{output_folder}/unwa\"\n",
        "\n",
        "if (input.endswith(extensions)):\n",
        "  input = f\"--input_file \\\"{input}\\\"\"\n",
        "else:\n",
        "  input = f\"--input_folder \\\"{input}\\\"\"\n",
        "\n",
        "if base_inference == True:\n",
        "  if base_model == 'VOCALS-BS-Roformer_1297 (by viperx)':\n",
        "    model_type = 'bs_roformer'\n",
        "    config_path = 'ckpts/model_bs_roformer_ep_317_sdr_12.9755.yaml'\n",
        "    start_check_point = 'ckpts/model_bs_roformer_ep_317_sdr_12.9755.ckpt'\n",
        "    download_file('https://raw.githubusercontent.com/ZFTurbo/Music-Source-Separation-Training/main/configs/viperx/model_bs_roformer_ep_317_sdr_12.9755.yaml')\n",
        "    download_file('https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/model_bs_roformer_ep_317_sdr_12.9755.ckpt')\n",
        "    conf_edit(config_path, chunk_size, overlap)\n",
        "\n",
        "  elif base_model == 'VOCALS-BS-Roformer_1296 (by viperx)':\n",
        "    model_type = 'bs_roformer'\n",
        "    config_path = 'ckpts/model_bs_roformer_ep_368_sdr_12.9628.yaml'\n",
        "    start_check_point = 'ckpts/model_bs_roformer_ep_368_sdr_12.9628.ckpt'\n",
        "    download_file('https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/model_bs_roformer_ep_368_sdr_12.9628.ckpt')\n",
        "    download_file('https://raw.githubusercontent.com/TRvlvr/application_data/main/mdx_model_data/mdx_c_configs/model_bs_roformer_ep_368_sdr_12.9628.yaml')\n",
        "    conf_edit(config_path, chunk_size, overlap)\n",
        "\n",
        "  elif base_model == 'VOCALS-MelBand-Roformer Kim FT (by Unwa)':\n",
        "    model_type = 'mel_band_roformer'\n",
        "    config_path = 'ckpts/config_kimmel_unwa_ft.yaml'\n",
        "    start_check_point = 'ckpts/kimmel_unwa_ft.ckpt'\n",
        "    download_file('https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/resolve/main/config_kimmel_unwa_ft.yaml')\n",
        "    download_file('https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/resolve/main/kimmel_unwa_ft.ckpt')\n",
        "    conf_edit(config_path, chunk_size, overlap)\n",
        "\n",
        "  elif base_model == 'VOCALS-BS-RoformerLargev1 (by unwa)':\n",
        "    model_type = 'bs_roformer'\n",
        "    config_path = 'ckpts/config_bsrofoL.yaml'\n",
        "    start_check_point = 'ckpts/BS-Roformer_LargeV1.ckpt'\n",
        "    download_file('https://huggingface.co/jarredou/unwa_bs_roformer/resolve/main/BS-Roformer_LargeV1.ckpt')\n",
        "    download_file('https://huggingface.co/jarredou/unwa_bs_roformer/raw/main/config_bsrofoL.yaml')\n",
        "    conf_edit(config_path, chunk_size, overlap)\n",
        "\n",
        "  elif base_model == 'VOCALS-Melband-Roformer BigBeta5e (by unwa)':\n",
        "    model_type = 'mel_band_roformer'\n",
        "    config_path = 'ckpts/big_beta5e.yaml'\n",
        "    start_check_point = 'ckpts/big_beta5e.ckpt'\n",
        "    download_file('https://huggingface.co/pcunwa/Mel-Band-Roformer-big/resolve/main/big_beta5e.ckpt')\n",
        "    download_file('https://huggingface.co/pcunwa/Mel-Band-Roformer-big/resolve/main/big_beta5e.yaml')\n",
        "    conf_edit(config_path, chunk_size, overlap)\n",
        "\n",
        "  elif base_model == 'VOCALS-Mel-Roformer big beta 4 (by unwa)':\n",
        "    model_type = 'mel_band_roformer'\n",
        "    config_path = 'ckpts/config_melbandroformer_big_beta4.yaml'\n",
        "    start_check_point = 'ckpts/melband_roformer_big_beta4.ckpt'\n",
        "    download_file('https://huggingface.co/pcunwa/Mel-Band-Roformer-big/resolve/main/melband_roformer_big_beta4.ckpt')\n",
        "    download_file('https://huggingface.co/pcunwa/Mel-Band-Roformer-big/raw/main/config_melbandroformer_big_beta4.yaml')\n",
        "    conf_edit(config_path, chunk_size, overlap)\n",
        "\n",
        "  elif base_model == 'VOCALS-MelBand-Roformer (by Becruily)':\n",
        "      model_type = 'mel_band_roformer'\n",
        "      config_path = 'ckpts/config_vocals_becruily.yaml'\n",
        "      start_check_point = 'ckpts/mel_band_roformer_vocals_becruily.ckpt'\n",
        "      download_file('https://huggingface.co/becruily/mel-band-roformer-vocals/resolve/main/config_vocals_becruily.yaml')\n",
        "      download_file('https://huggingface.co/becruily/mel-band-roformer-vocals/resolve/main/mel_band_roformer_vocals_becruily.ckpt')\n",
        "      conf_edit(config_path, chunk_size, overlap)\n",
        "\n",
        "  if base_inference == True:\n",
        "    print(f\"STARTING BASE MODEL INFERENCE\")\n",
        "    !python inference.py \\\n",
        "      --model_type {model_type} \\\n",
        "      --config_path '{config_path}' \\\n",
        "      --start_check_point '{start_check_point}' \\\n",
        "      {input} \\\n",
        "      --store_dir '{output_base}' \\\n",
        "      --extract_instrumental \\\n",
        "      {('--flac_file' if flac_file else '')} \\\n",
        "      {('--pcm_type ' + pcm_type if pcm_type else '')}\n",
        "\n",
        "if unwa_inference == True:\n",
        "  if unwa_model == 'INST-Mel-Roformer v1 (by unwa)':\n",
        "    model_type = 'mel_band_roformer'\n",
        "    config_path = 'ckpts/config_melbandroformer_inst.yaml'\n",
        "    start_check_point = 'ckpts/melband_roformer_inst_v1.ckpt'\n",
        "    download_file('https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/resolve/main/melband_roformer_inst_v1.ckpt')\n",
        "    download_file('https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/raw/main/config_melbandroformer_inst.yaml')\n",
        "    conf_edit(config_path, chunk_size, overlap)\n",
        "\n",
        "  elif unwa_model == 'INST-Mel-Roformer v2 (by unwa)':\n",
        "    model_type = 'mel_band_roformer'\n",
        "    config_path = 'ckpts/config_melbandroformer_inst_v2.yaml'\n",
        "    start_check_point = 'ckpts/melband_roformer_inst_v2.ckpt'\n",
        "    download_file('https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/resolve/main/melband_roformer_inst_v2.ckpt')\n",
        "    download_file('https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/raw/main/config_melbandroformer_inst_v2.yaml')\n",
        "    conf_edit(config_path, chunk_size, overlap)\n",
        "\n",
        "  elif unwa_model == 'INST-Mel-Roformer v1e (by unwa)':\n",
        "    model_type = 'mel_band_roformer'\n",
        "    config_path = 'ckpts/config_melbandroformer_inst.yaml'\n",
        "    start_check_point = 'ckpts/inst_v1e.ckpt'\n",
        "    download_file('https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/resolve/main/inst_v1e.ckpt')\n",
        "    download_file('https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/raw/main/config_melbandroformer_inst.yaml')\n",
        "    conf_edit(config_path, chunk_size, overlap)\n",
        "\n",
        "  elif unwa_model == 'INST-VOC-Mel-Roformer a.k.a. duality (by unwa)':\n",
        "    model_type = 'mel_band_roformer'\n",
        "    config_path = 'ckpts/config_melbandroformer_instvoc_duality.yaml'\n",
        "    start_check_point = 'ckpts/melband_roformer_instvoc_duality_v1.ckpt'\n",
        "    download_file('https://huggingface.co/pcunwa/Mel-Band-Roformer-InstVoc-Duality/resolve/main/melband_roformer_instvoc_duality_v1.ckpt')\n",
        "    download_file('https://huggingface.co/pcunwa/Mel-Band-Roformer-InstVoc-Duality/raw/main/config_melbandroformer_instvoc_duality.yaml')\n",
        "    conf_edit(config_path, chunk_size, overlap)\n",
        "\n",
        "  elif unwa_model == 'INST-VOC-Mel-Roformer a.k.a. duality v2 (by unwa)':\n",
        "    model_type = 'mel_band_roformer'\n",
        "    config_path = 'ckpts/config_melbandroformer_instvoc_duality.yaml'\n",
        "    start_check_point = 'ckpts/melband_roformer_instvox_duality_v2.ckpt'\n",
        "    download_file('https://huggingface.co/pcunwa/Mel-Band-Roformer-InstVoc-Duality/resolve/main/melband_roformer_instvox_duality_v2.ckpt')\n",
        "    download_file('https://huggingface.co/pcunwa/Mel-Band-Roformer-InstVoc-Duality/raw/main/config_melbandroformer_instvoc_duality.yaml')\n",
        "    conf_edit(config_path, chunk_size, overlap)\n",
        "\n",
        "  elif unwa_model == 'INST-MelBand-Roformer (by Becruily)':\n",
        "      model_type = 'mel_band_roformer'\n",
        "      config_path = 'ckpts/config_instrumental_becruily.yaml'\n",
        "      start_check_point = 'ckpts/mel_band_roformer_instrumental_becruily.ckpt'\n",
        "      download_file('https://huggingface.co/becruily/mel-band-roformer-instrumental/resolve/main/config_instrumental_becruily.yaml')\n",
        "      download_file('https://huggingface.co/becruily/mel-band-roformer-instrumental/resolve/main/mel_band_roformer_instrumental_becruily.ckpt')\n",
        "      conf_edit(config_path, chunk_size, overlap)\n",
        "\n",
        "  if unwa_inference == True:\n",
        "    clear_output(wait=True)\n",
        "    print(f\"STARTING UNWA MODEL INFERENCE\")\n",
        "    !python inference.py \\\n",
        "      --model_type {model_type} \\\n",
        "      --config_path '{config_path}' \\\n",
        "      --start_check_point '{start_check_point}' \\\n",
        "      {input} \\\n",
        "      --store_dir '{output_unwa}' \\\n",
        "      {('--flac_file' if flac_file else '')} \\\n",
        "      {('--pcm_type ' + pcm_type if pcm_type else '')}\n",
        "\n",
        "#if phasefix_testmode == True:\n",
        "if base_inference == True and unwa_inference == True:\n",
        "  clear_output(wait=True)\n",
        "  print(f\"Starting Phase Fixing process...\")\n",
        "  time.sleep(8)\n",
        "!python torch_colab.py --base_folder '{output_base}' --unwa_folder '{output_unwa}' --output_folder {output_folder}"
      ],
      "metadata": {
        "id": "CCRJCgf9fmjw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**base_inference/unwa_inference** - enables the inference process for the selected model.<br>\n",
        "Disabling both goes right to the phase fixing process.<br>\n",
        "**phase fixing process** looks for pairs of files in base and unwa foders, inside the output directory.<br>For base outputs files must have \"_instrumental\" appended. For unwa outputs files must have \"_other\" appended.<br>\n",
        "**Overlap** - higher means longer separation time. 4 is already balanced value, 2 is fast and some people still won't notice any difference. Normally there's not point going over 8."
      ],
      "metadata": {
        "id": "F0naaH9Dfs-H"
      }
    }
  ]
}